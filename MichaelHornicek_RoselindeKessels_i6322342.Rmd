---
title: "Knowledge Discovery and Data Visualization Exam"
author: "Michael Hornicek"
date: "2022-12-22"
tutor_name: "Roselinde Kessels"
tutor_number: "i6322342"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(cache =TRUE)
```

## Question 1

Open data set and generate random subset of 480 observations

```{r}
# read file
housing <- read.csv(
  file="./housing.csv",
  sep = ";",
  header = FALSE,
  col.names = c("CRIM", "ZN", "INDUS", "CHAS", "NOX", "RM", "AGE", "DIS", "RAD", "TAX", "PTRATIO", "B", "LSTAT", "MEDV")
)

# get random subset
set.seed(0)
index <- sample(1:nrow(housing), 480)
housing_subset <- housing[index, ]
summary(housing_subset)
```

## Question 2

### Pre-processing

To start pre-processing, first check if there are any missing values.

```{r}
# check for NA values
na_count <- sapply(housing_subset, function(value) sum(length(which(is.na(value)))))
na_count <- data.frame(na_count)
na_count
```

There are no missing values.

### Outliers

Next, let's try to find outliers. In order to find outliers, and simultaneously gain some insight into the distribution of values, 
a histogram can be plotted. I plotted histograms for each variable using both the 
original values, and Z-score standardized values. 

#### CRIM

The first variable, CRIM, which is the per capita crime rate of the town/sub-urb,
does have outliers. These are the histograms, using both the raw values, and the z-score standardized values:

```{r}
# CRIME histogram
par(mfrow=c(1, 2))
hist(housing_subset$CRIM,
     col="blue",
     border="black",
     xlab="Per capita crime rate",
     ylab="counts",
     main="Crime rate per cap. hist.")
box(which="plot", lty="solid", col="black")

z_score_CRIM <- ((housing_subset$CRIM-mean(housing_subset$CRIM))/sd(housing_subset$CRIM))

hist(z_score_CRIM,
     breaks=10,
     col="blue",
     border="black",
     xlim = c(-2, 12),
     ylim = c(0, 100),
     xlab="Z-standardized per capita crime rate",
     ylab="count",
     main="Z-stand. crime rate per cap. hist.")
axis(side=1)
box(which="plot", lty="solid", col="black")
```

And if we want to have a look at the rows producing these outliers:

```{r}
housing_subset$CRIM_z <- ((housing_subset$CRIM-mean(housing_subset$CRIM))/sd(housing_subset$CRIM))


outliers <- housing_subset[housing_subset$CRIM_z > 3, ]
outliers
nrow(outliers)
```

And for a summary of the z-score for the CRIM variable:

```{r}
summary(housing_subset$CRIM_z)
```

There are values with extremely high z-scores, considering that an outlier is considered to be any variable with a z-score greater than 3 (or less than -3), and
here we have a value of 9.73, and two more values of 7.969 and 7.329. However,
I don't know enough about the meaning of the CRIM variable (for example what its units are), to be able to say whether these values are so extreme that they must not be correct, or whether it is possible that they are correct.

#### ZN

The ZN variable, which is the proportion of residental land zoned for lots over 25000 sq ft also has outliers:

```{r}
par(mfrow=c(1, 2))
hist(housing_subset$ZN,
     col="blue",
     border="black",
     xlab="Prop. of res. land zoned for lots >25k sq ft",
     ylab="counts",
     main="Hist. of residential land zoning")
box(which="plot", lty="solid", col="black")

housing_subset$ZN_z <- ((housing_subset$ZN-mean(housing_subset$ZN))/sd(housing_subset$ZN))

hist(housing_subset$ZN_z,
     breaks=10,
     col="blue",
     border="black",
     xlim = c(-6, 6),
     xlab="Z-score prop. of res. land zoned for lots >25k sq ft",
     ylab="count",
     main="Hist. of z-score residential land zoning")
box(which="plot", lty="solid", col="black")
```

These are the records:

```{r}
housing_subset[housing_subset$ZN_z > 3, ]

nrow(housing_subset[housing_subset$ZN_z > 3, ])
```

While there are more outliers here compared to CRIM (13 here vs 8 for CRIM), their 
values are nowhere near as extreme, with the most extreme outlier having a z-score
of 3.80.

#### RM

The next variable containing outliers (as classified using z-score) is RM, which is the average number of rooms per house.

```{r}
par(mfrow=c(1, 2))
hist(housing_subset$RM,
     col="blue",
     border="black",
     xlab="Avg number of rooms",
     ylab="counts",
     main="Hist. avg no. of rooms")
box(which="plot", lty="solid", col="black")

housing_subset$RM_z <- ((housing_subset$RM-mean(housing_subset$RM))/sd(housing_subset$RM))

hist(housing_subset$RM_z,
     breaks=10,
     col="blue",
     border="black",
     xlim = c(-6, 6),
     xlab="Hist. z-score avg. no. of rooms",
     ylab="counts",
     main="Hist. z-score avg. no. of rooms")
box(which="plot", lty="solid", col="black")
```

There are 8 outliers, which is a similar amount to other quantities. Their values are not very extreme either, with the greatest outlier having a z-score of -3.88.

```{r}
outliers <- housing_subset[housing_subset$RM_z > 3 | housing_subset$RM_z < -3, ]

nrow(outliers)

summary(housing_subset$RM_z)
```

#### DIS

The next variable with outliers is the DIS variable, representing the weighted distances to 5 Boston employment centers.

```{r}
par(mfrow=c(1, 2))
hist(housing_subset$DIS,
     col="blue",
     border="black",
     xlab="Distance from empl. centres",
     ylab="counts",
     main="Hist. of distance from empl. centres")
box(which="plot", lty="solid", col="black")

housing_subset$DIS_z <- ((housing_subset$DIS-mean(housing_subset$DIS))/sd(housing_subset$DIS))

hist(housing_subset$DIS_z,
     breaks=10,
     col="blue",
     border="black",
     xlim = c(-6, 6),
     xlab="Z-score distance from empl. centres",
     ylab="counts",
     main="Hist. of distance from empl. centres")
box(which="plot", lty="solid", col="black")
```

The records:

```{r}
housing_subset[housing_subset$DIS_z > 3, ]

nrow(housing_subset[housing_subset$DIS_z > 3, ])

summary(housing_subset$DIS_z)
```

Compared to other variables, DIS has 5 outliers, which is relatively few. Their values are also not particularly extreme, with the greatest outlier having a z-score of 3.91.

#### B

The next variable with outliers is the B variable, which is linked to the proportion of the black population in the town.

```{r}
par(mfrow=c(1, 2))
hist(housing_subset$B,
     col="blue",
     border="black",
     xlab="1000(Bk - 0.63)^2",
     ylab="counts",
     main="Hist. of 1000(Bk - 0.63)^2")
box(which="plot", lty="solid", col="black")

housing_subset$B_z <- ((housing_subset$B-mean(housing_subset$B))/sd(housing_subset$B))

hist(housing_subset$B_z,
     breaks=10,
     col="blue",
     border="black",
     xlim = c(-6, 6),
     xlab="Z-score 1000(Bk - 0.63)^2",
     ylab="counts",
     main="Hist. of z-score 1000(Bk - 0.63)^2")
box(which="plot", lty="solid", col="black")
```

These are the records:

```{r}
housing_subset[housing_subset$B_z < -3, ]

nrow(housing_subset[housing_subset$B_z < -3, ])

summary(housing_subset$B_z)
```

Unlike for other variables, this one has outliers mainly to the left of the center.
There are also relatively many, at 23. Though their values are not very extreme, with the most extreme having a z-score of -3.87.


#### LSTAT

The next variable with outliers is the LSTAT variable, representing the % of lower status of the population.

```{r}
# LSTAT histogram
par(mfrow=c(1, 2))
hist(housing_subset$LSTAT,
     col="blue",
     border="black",
     xlab="Proportion of lower status",
     ylab="counts",
     main="Hist. of prop. of lower status")
box(which="plot", lty="solid", col="black")

housing_subset$LSTAT_z <- ((housing_subset$LSTAT-mean(housing_subset$LSTAT))/sd(housing_subset$LSTAT))

hist(housing_subset$LSTAT_z,
     breaks=10,
     col="blue",
     border="black",
     xlim = c(-6, 6),
     xlab="Z-standardized proportion of lower status",
     ylab="counts",
     main="Hist. of z-score prop. of lower status")
box(which="plot", lty="solid", col="black")
```

These are the records:

```{r}

housing_subset[housing_subset$LSTAT_z > 3, ]
nrow(housing_subset[housing_subset$LSTAT_z > 3, ])
summary(housing_subset$LSTAT_z)
```

This variable also has relatively few outliers with not very extreme, with the most extreme having a z-score of 3.54.

### Correlations analysis of numeric variables

Below are  correlation coefficients between all the numeric variables and the target variable:

```{r}
# Collect variables of interest
corrdata <- cbind(housing_subset$CRIM,
                  housing_subset$ZN,
                  housing_subset$INDUS,
                  housing_subset$NOX,
                  housing_subset$RM,
                  housing_subset$AGE,
                  housing_subset$DIS,
                  housing_subset$RAD,
                  housing_subset$TAX,
                  housing_subset$PTRATIO,
                  housing_subset$B,
                  housing_subset$LSTAT,
                  housing_subset$MEDV)
# Declare the matrix
corrpvalues <- matrix(rep(0, 169),
                      ncol = 13)
# Fill the matrix with correlations
for (i in 1:12) {
  for (j in (i+1):13) {
    corrpvalues[i,j] <- corrpvalues[j,i] <-
      round(cor.test(corrdata[,i],
                     corrdata[,j])$p.value,
            4)
  }
}

correlations <- round(cor(corrdata), 4)
colnames(correlations) <- c("CRIM", "ZN", "INDUS", "NOX", "RM", "AGE", "DIS", "RAD", "TAX", "PTRATIO", "B", "LSTAT", "MEDV")
rownames(correlations) <- c("CRIM", "ZN", "INDUS", "NOX", "RM", "AGE", "DIS", "RAD", "TAX", "PTRATIO", "B", "LSTAT", "MEDV")
correlations
```

### Frequency tables for categorical variables

Below is a frequency table for the only categorical variable in the data set, CHAS, which indicates whether the neighborhood is by the river or not. In order to create a frequency table and correlate the categorical variable CHAS with the numeric target variable, I decided to use equal binning of the variable. Note that bin 0 is the most expensive houses and bin 4 the cheapest.

```{r}
# bin house values - equal binning

xdata <- housing_subset$MEDV
n <- length(xdata)
nbins <- 4
whichbin <- c(rep(0, n))
range_xdata <- max(xdata) - min(xdata) + 1
binwidth <- range_xdata/nbins
for (i in 1:nbins) {
  for (j in 1:n) {
    if((i-1)*binwidth < xdata[j] &&
       xdata[j] <= (i)*binwidth)
      whichbin[j] <- i
  }
}

housing_subset$MEDV_bin <- whichbin

table(housing_subset$MEDV_bin, housing_subset$CHAS, dnn=c("MEDV bin", "CHAS"))
```

### Analysis / interesting relationships

#### Crime and median house value

In terms of interesting relationships between the target variable and other variables, in my opinion, the relationships where there was a low correlation were more interesting. The strongest correlations occurred for variables which I would expect to be strongly correlated, such as the average number of rooms per dwelling and the percentage of lower status of the population. It seems quite obvious that those would be correlated with the median house value.

On the other hand, I was surprised that crime had one of the lowest correlation coefficients (-0.3868). This is what the scatter plot looks like:

```{r}
plot(housing_subset$MEDV, housing_subset$CRIM,
     xlab = "Median house value $1000s",
     ylab = "Per capita crime rate",
     main = "Scatter plot of crime rate against median house value",
     type = "p",
     pch = 16,
     col = "blue")
```

For lower median house values (circa below 30k), the scatter plot looks like what I would expect, as the median house value increases, the crime rate decreases. After 30k, the crime rate remains stable, which also makes sense, because it is quite close to 0, and it can't go lower. Unexpectedly, at 50k, there are some suburbs with higher than expected crime rates.

```{r}
most_expensive <- housing_subset[housing_subset$MEDV > 49, ]
most_expensive_sorted <- most_expensive[order(most_expensive$CRIM), ]
most_expensive_sorted
```

When we look at the data for those houses, sorted by crime, a trend emerges. For these most expensive houses, there seems to be a very strong correlation between CRIM and DIS. The neighborhoods which have expensive houses and relatively higher crime, they very low distance to employment centres. This kind of makes sense - those properties tend to be expensive, and the people living there might be willing to accept higher levels of crime in exchange for being very close to the center.

```{r}
fit <- lm(most_expensive$CRIM ~ most_expensive$DIS)
summary(fit)
```

```{r}
fit <- lm(housing_subset$CRIM ~ housing_subset$DIS)
summary(fit)
```

As we can see, this correlation seems to be unique to these expensive properties, and explains part of the reason why the correlation between crime and house values is not as high as I would have expected.

#### Distance and median house value

Another interesting relationship, kind of related to the previous one, is between the distance to employment centres and median house values. This one actually has the lowest correlation to median house values, which I was also surprised by. Here is the scatter plot:

```{r}
plot(housing_subset$MEDV, housing_subset$DIS,
     xlab = "Median house value $1000s",
     ylab = "Distance from empl. centres",
     main = "Scatterplot of DIS against median house value",
     type = "p",
     pch = 16,
     col = "blue")
```

Describing the trend in the scatter plot has some similarities with the crime rate trend. Up until a median house value of about 30k, there is a relatively strong correlation between distance from employment centres and the median house value. This is actually opposite of what I expected, I would expect prices to decreases as one gets further away from the center. And then after the price surpasses about 30k, the trend kind of reverses - as price increases, distance decreases. 

This suggests that sub-urban areas, which are further away from the centre ten to be quite middle class (since houses of average value tend to be found there). On the other hand, areas close to the center of town seem to be either very rich, or very poor. 

#### Nitrous oxide pollution and median house value

The relationship between nitric oxides and median house value also seems to be in line with the hypothesis that the sub-urban areas, further away from the center tend to be middle class and the center has relatively poor and relatively rich people living there. Again, the NOX variable has a relatively low correlation to the median house value. Here is the scatter plot:

```{r}
plot(housing_subset$MEDV, housing_subset$NOX,
     xlab = "Median house value",
     ylab = "Nitric oxide concentration",
     main = "Scatterplot of NOX against median house value",
     type = "p",
     pch = 16,
     col = "blue")
```

Like with crime, the scatter has kind of a U shape, where the neighborhoods with the lowest house values and those with the highest house values both tned to have relatively high concentration of polluting nitrous oxides. On the other hand, the more average neighborhoods (in terms of their median house value) tend to have lower nitrous oxide pollution.


### Question 3

#### Partition into training and testing

```{r}
housing_subset$part <- runif(nrow(housing_subset), min=0, max=1)
training <- housing_subset[housing_subset$part <=0.75, ]
testing <- housing_subset[housing_subset$part > 0.75, ]
```

#### Validate partition

```{r}
testing_sample_mean <- mean(testing$MEDV)
training_sample_mean <- mean(training$MEDV)

testing_sample_mean; training_sample_mean

testing_sample_size <- nrow(testing)
training_sample_size <- nrow(training)

testing_sample_sd <- sd(testing$MEDV)
training_sample_sd <- sd(training$MEDV)

dfs <- min(testing_sample_size, training_sample_size)

t_data <- (testing_sample_mean - training_sample_mean) / sqrt((training_sample_sd^2 / training_sample_size) + (testing_sample_mean^2 / testing_sample_size))

p_value <- 2*pt(t_data, df=dfs, lower.tail=FALSE)

t_data;p_value
```

Since the predictive variable is numeric, we use the two-sample t-Test for difference in means between the training sample mean and the testing sample mean. In this case, the p value is large, so there is no evidence that the average median house value differs between the training data and the test data set. 
#### Data mining models

##### KNN

```{r}
library(class)

testing$MEDV_bin_pred_knn <- knn(training, testing, cl=training$MEDV_bin, k=5, prob=TRUE)

head(testing)

cm = as.matrix(table(Actual = testing$MEDV_bin, Predicted = testing$MEDV_bin_pred_knn))

sum(diag(cm))/length(training$MEDV_bin)
```

First, I decided to use a K nearest neighbour data mining model. I used the same binning of the target variable, as in question 2, ie 5 equal bin. The model then uses the the other variables in the model in order to predict which bin the neighborhood would go into. I decided to use the z-normalized version of the variables, in order to normalize the distances of the variables that the kNN algorithm uses.

I use a confusion matrix in order to evaluate the model. The overall error rate is 0.199. I optimized k to 5, such that the error rate would decrease to this level.

##### CART

```{r}
library("rpart"); library("rpart.plot")

# normalize values

testing$INDUS_z <- ((testing$INDUS-mean(testing$INDUS))/sd(testing$INDUS))

testing$NOX_z <- ((testing$NOX-mean(testing$NOX))/sd(testing$NOX))

testing$AGE_z <- ((testing$AGE-mean(testing$AGE))/sd(testing$AGE))

testing$TAX_z  <- ((testing$TAX-mean(testing$TAX))/sd(testing$TAX))

# bin MEDV into two values:

xdata <- testing$MEDV
n <- length(xdata)
nbins <- 2
whichbin <- c(rep(0, n))
range_xdata <- max(xdata) - min(xdata) + 1
binwidth <- range_xdata/nbins
for (i in 1:nbins) {
  for (j in 1:n) {
    if((i-1)*binwidth < xdata[j] &&
       xdata[j] <= (i)*binwidth)
      whichbin[j] <- i
  }
}

testing$MEDV_expensive <- whichbin



cartfit <- rpart(testing$MEDV_expensive ~ testing$CRIM_z + testing$ZN_z + testing$INDUS_z + testing$NOX_z + testing$AGE_z + testing$DIS_z + testing$TAX_z, data=testing, method="class")

rpart.plot(cartfit)
```

The second data mining model I used is the CART model. I first normalized the variables, which must be done when using the CART model. I also changed the binning of the target variable. Instead of the previous 5 bins, when using a decision tree model one of the requirements is that the target variable is a discrete value, as either belonging to a group, or not belonging to a group. So I decided to use only two bins of equal size, such that it is divided into a bin of median house value <$25k and above. The CART model chose the ZN variable as the root, the most important one, followed by TAX and DIS

```{r}
library("C50")
x <- testing[,c("CRIM_z","ZN_z", "INDUS_z", "NOX_z", "AGE_z", "DIS_z", "TAX_z")] 
y <- as.factor(testing$MEDV_bin)
c50fit <- C5.0(x, y)
summary(c50fit)
```

Lastly, I decided to also use the C5.0 model, which is an update on the CART model. The C5.0 model determined the DIS variable as the most important variable. 